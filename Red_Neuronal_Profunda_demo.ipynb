{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Red_Neuronal_Profunda_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtaSkXJWHb38dWfG0wVG2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniomarquina/tensorflow/blob/master/Red_Neuronal_Profunda_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6wcdQsLdbVt"
      },
      "source": [
        "# **Red Neuronal \"Profunda\" en PyTorch**\"\n",
        "\n",
        "Recordar cambiar el entorno de ejecución a GPU o TPU si trabajamos en Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXZYD4gleGJ9"
      },
      "source": [
        "### Descarga de las dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkgJR0OBeRgE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgbTrfZQgl1N"
      },
      "source": [
        "#### Descarga de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfa2aa49g4Ah"
      },
      "source": [
        "train = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test = MNIST('data', train=False, transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovHo-sRFhESa"
      },
      "source": [
        "#### Batch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmKD9TbYhM7s"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128) \n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv1lp9OIhVRh"
      },
      "source": [
        "#### Diseño de la arquitectura de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSEwOH74hb6e"
      },
      "source": [
        "n_input = 784\n",
        "n_dense_1 = 64\n",
        "n_dense_2 = 64\n",
        "n_dense_3 = 64\n",
        "n_out = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV5w6ADVhj5l"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    \n",
        "    # first hidden layer: \n",
        "    nn.Linear(n_input, n_dense_1), \n",
        "    nn.ReLU(), \n",
        "    \n",
        "    # second hidden layer: \n",
        "    nn.Linear(n_dense_1, n_dense_2), \n",
        "    nn.ReLU(), \n",
        "    \n",
        "    # third hidden layer: \n",
        "    nn.Linear(n_dense_2, n_dense_3), \n",
        "    nn.ReLU(), \n",
        "    nn.Dropout(),  \n",
        "    \n",
        "    # output layer: \n",
        "    nn.Linear(n_dense_3, n_out) \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meNgW0cwhrBM"
      },
      "source": [
        "summary(model, (1, n_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws0IuzGph1r9"
      },
      "source": [
        "#### Configuración de los hiper-parámetros de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0f0NocVh9Xs"
      },
      "source": [
        "cost_fxn = nn.CrossEntropyLoss() # includes softmax activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVPHFBTih9jo"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXS0H0dPiRYV"
      },
      "source": [
        "#### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgQwdKfviV0-"
      },
      "source": [
        "def accuracy_pct(pred_y, true_y):\n",
        "  _, prediction = torch.max(pred_y, 1) # returns maximum values, indices; fed tensor, dim to reduce\n",
        "  correct = (prediction == true_y).sum().item()\n",
        "  return (correct / true_y.shape[0]) * 100.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjEQv4Bmibsp"
      },
      "source": [
        "n_batches = len(train_loader)\n",
        "n_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y8H3Z3-ib4l"
      },
      "source": [
        "n_epochs = 10 \n",
        "\n",
        "print('Training for {} epochs. \\n'.format(n_epochs))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  avg_cost = 0.0\n",
        "  avg_accuracy = 0.0\n",
        "  \n",
        "  for i, (X, y) in enumerate(train_loader): # enumerate() provides count of iterations  \n",
        "    \n",
        "    # forward propagation:\n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_cost += cost / n_batches\n",
        "    \n",
        "    # backprop and optimization via gradient descent: \n",
        "    optimizer.zero_grad() # set gradients to zero; .backward() accumulates them in buffers\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # calculate accuracy metric:\n",
        "    accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_accuracy += accuracy / n_batches\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Step {}'.format(i + 1))\n",
        "    \n",
        "  print('Epoch {}/{} complete: Cost: {:.3f}, Accuracy: {:.1f}% \\n'\n",
        "        .format(epoch + 1, n_epochs, avg_cost, avg_accuracy)) \n",
        "\n",
        "print('Training complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cItfboMdiwzZ"
      },
      "source": [
        "#### Validación con los datos de grupo de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttQwNwCdi4ZL"
      },
      "source": [
        "n_test_batches = len(test_loader)\n",
        "n_test_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CNOePXki-iJ"
      },
      "source": [
        "model.eval() # disables dropout and batch norm\n",
        "\n",
        "with torch.no_grad(): # disables autograd, reducing memory consumption\n",
        "  \n",
        "  avg_test_cost = 0.0\n",
        "  avg_test_acc = 0.0\n",
        "  \n",
        "  for X, y in test_loader:\n",
        "    \n",
        "    # make predictions: \n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    \n",
        "    # calculate cost: \n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_test_cost += cost / n_test_batches\n",
        "    \n",
        "    # calculate accuracy:\n",
        "    test_accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_test_acc += test_accuracy / n_test_batches\n",
        "\n",
        "print('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))\n",
        "\n",
        "# model.train() # 'undoes' model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}